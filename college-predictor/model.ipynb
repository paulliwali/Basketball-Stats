{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Net(\n  (hidden1): Linear(in_features=18, out_features=12, bias=True)\n  (output): Linear(in_features=12, out_features=1, bias=True)\n  (sigmoid): Sigmoid()\n  (elu): ELU(alpha=1.0)\n)\n"}],"source":"class Net(nn.Module):\n    \n    def __init__(self):\n        super(Net, self).__init__()\n        # Inputs to hidden layer\n        self.hidden1 = nn.Linear(18, 12)\n        # Output layer\n        self.output = nn.Linear(12, 1)\n        self.sigmoid = nn.Sigmoid()\n        self.elu = nn.ELU()\n    \n    def forward(self, x):\n        # Pass the input tensor through the following\n        x = self.hidden1(x)\n        x = self.elu(x)\n        x = self.output(x)\n        x = self.sigmoid(x)\n        return x\n    \n    def num_flat_features(self, x):\n        size = x.size()[1:]  # all dimensions except the batch dimension\n        num_features = 1\n        for s in size:\n            num_features *= s\n        return num_features\n    \nnet = Net()\nprint(net)"},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":"# Define inputs and target\ncurrent_dir = Path.cwd() / \"college-predictor\"\ninput_df = pd.read_csv(current_dir / \"data/working\" / \"2000-2017-pace.csv\", comment = \"#\")\nx = input_df.iloc[:,4:22]\ny = input_df.iloc[:,3]\ninput = torch.tensor(x.values.astype(np.float32))\ntarget = torch.tensor(y.values.astype(np.float32))"},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"tensor(0.7976, grad_fn=<MseLossBackward>)\n"}],"source":"# Define loss function\noutput = net(input)\ncriterion = nn.MSELoss()\n\nloss = criterion(output, target)\nprint(loss)"},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":"# Define optimizer\nlearning_rate = 0.01\noptimizer = optim.SGD(net.parameters(), lr = learning_rate)\noptimizer.zero_grad()"},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"training loss: 0.7976190447807312\n"}],"source":"# Update the weights\nepochs = 10\nfor e in range(epochs):\n    running_loss = 0\n    output = net(input)  # foward pass\n    loss = criterion(output, target)  # calculate loss\n    loss.backward() # calculate gradients\n    optimizer.step() # update weights with optimizer\n    running_loss += loss.item()\nprint(f\"training loss: {running_loss}\")"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}
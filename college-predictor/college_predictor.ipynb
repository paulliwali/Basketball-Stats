{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "college-predictor.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulliwali/Basketball-Stats/blob/master/college-predictor/college_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "luHkDZUhvNQE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NBA College Player Predictor\n",
        "(An attempt at using Colaboratory)"
      ]
    },
    {
      "metadata": {
        "id": "s7eA3AWG2XdI",
        "colab_type": "code",
        "outputId": "59809b24-9138-425b-d3bf-88f707630a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.losses import binary_crossentropy, mean_squared_error\n",
        "from keras.activations import relu, elu, sigmoid\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "7mSGyk9Z3OGE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Files"
      ]
    },
    {
      "metadata": {
        "id": "1eDD5zFpuwI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "327af964-4583-44c6-e596-58be576ffd0b"
      },
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/paulliwali/Basketball-Stats/master/college-predictor/data/2010-2017-pace.csv'\n",
        "df = pd.read_csv(url)\n",
        "display(df.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(240, 26)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "r2kS1M1kwBTV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data Munging**"
      ]
    },
    {
      "metadata": {
        "id": "LqgERaKD3-1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2b1c1bfb-454a-4945-f686-aacea33c8236"
      },
      "cell_type": "code",
      "source": [
        "df.rename({'IsSuccessful':'y'}, axis=1, inplace=True)\n",
        "df = df.loc[df['College Pace']!='Did Not Attend College',:]\n",
        "df = df.loc[df['College Pace']!='Wrong College Found',:]\n",
        "df = df.iloc[:,3:]\n",
        "df.drop('College Name', axis=1, inplace=True)\n",
        "display(df.shape)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(203, 22)"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "H1QN8c_TxTkP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Split X and y"
      ]
    },
    {
      "metadata": {
        "id": "5paM5AEHxSef",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "ed54aab6-4dae-4e33-9edc-0394870165c0"
      },
      "cell_type": "code",
      "source": [
        "display(df.head())\n",
        "X = df[[col for col in df.columns if 'y' not in col]]\n",
        "y = df[[col for col in df.columns if 'y' in col]] \n",
        "\n",
        "X = X.astype(float)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>MP</th>\n",
              "      <th>FG</th>\n",
              "      <th>FGA</th>\n",
              "      <th>3P</th>\n",
              "      <th>3Pa</th>\n",
              "      <th>FT</th>\n",
              "      <th>FTA</th>\n",
              "      <th>...</th>\n",
              "      <th>AST</th>\n",
              "      <th>STL</th>\n",
              "      <th>BLK</th>\n",
              "      <th>TOV</th>\n",
              "      <th>PF</th>\n",
              "      <th>PTS</th>\n",
              "      <th>College Pace</th>\n",
              "      <th>OffRtg</th>\n",
              "      <th>DefRtg</th>\n",
              "      <th>Years in College</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>193</td>\n",
              "      <td>88</td>\n",
              "      <td>1288</td>\n",
              "      <td>202</td>\n",
              "      <td>438</td>\n",
              "      <td>37</td>\n",
              "      <td>114</td>\n",
              "      <td>175</td>\n",
              "      <td>232</td>\n",
              "      <td>...</td>\n",
              "      <td>241</td>\n",
              "      <td>66</td>\n",
              "      <td>19</td>\n",
              "      <td>149</td>\n",
              "      <td>72</td>\n",
              "      <td>616</td>\n",
              "      <td>70.7</td>\n",
              "      <td>112.1</td>\n",
              "      <td>91.8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>201</td>\n",
              "      <td>100</td>\n",
              "      <td>1108</td>\n",
              "      <td>539</td>\n",
              "      <td>1073</td>\n",
              "      <td>54</td>\n",
              "      <td>149</td>\n",
              "      <td>385</td>\n",
              "      <td>508</td>\n",
              "      <td>...</td>\n",
              "      <td>414</td>\n",
              "      <td>159</td>\n",
              "      <td>74</td>\n",
              "      <td>352</td>\n",
              "      <td>86</td>\n",
              "      <td>1517</td>\n",
              "      <td>60.8</td>\n",
              "      <td>115.4</td>\n",
              "      <td>102.3</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>208</td>\n",
              "      <td>120</td>\n",
              "      <td>989</td>\n",
              "      <td>179</td>\n",
              "      <td>293</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>90</td>\n",
              "      <td>143</td>\n",
              "      <td>...</td>\n",
              "      <td>37</td>\n",
              "      <td>32</td>\n",
              "      <td>74</td>\n",
              "      <td>90</td>\n",
              "      <td>94</td>\n",
              "      <td>448</td>\n",
              "      <td>70.6</td>\n",
              "      <td>103.1</td>\n",
              "      <td>93.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>201</td>\n",
              "      <td>98</td>\n",
              "      <td>1224</td>\n",
              "      <td>462</td>\n",
              "      <td>1017</td>\n",
              "      <td>130</td>\n",
              "      <td>373</td>\n",
              "      <td>239</td>\n",
              "      <td>311</td>\n",
              "      <td>...</td>\n",
              "      <td>150</td>\n",
              "      <td>106</td>\n",
              "      <td>108</td>\n",
              "      <td>138</td>\n",
              "      <td>72</td>\n",
              "      <td>1293</td>\n",
              "      <td>71</td>\n",
              "      <td>114</td>\n",
              "      <td>93.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>211</td>\n",
              "      <td>122</td>\n",
              "      <td>893</td>\n",
              "      <td>206</td>\n",
              "      <td>369</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>162</td>\n",
              "      <td>268</td>\n",
              "      <td>...</td>\n",
              "      <td>38</td>\n",
              "      <td>37</td>\n",
              "      <td>67</td>\n",
              "      <td>78</td>\n",
              "      <td>122</td>\n",
              "      <td>575</td>\n",
              "      <td>70.7</td>\n",
              "      <td>112.1</td>\n",
              "      <td>91.8</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   y  Height  Weight    MP   FG   FGA   3P  3Pa   FT  FTA       ...         \\\n",
              "0  1     193      88  1288  202   438   37  114  175  232       ...          \n",
              "1  0     201     100  1108  539  1073   54  149  385  508       ...          \n",
              "2  0     208     120   989  179   293    0    1   90  143       ...          \n",
              "3  0     201      98  1224  462  1017  130  373  239  311       ...          \n",
              "4  1     211     122   893  206   369    1    6  162  268       ...          \n",
              "\n",
              "   AST  STL  BLK  TOV   PF   PTS  College Pace  OffRtg DefRtg Years in College  \n",
              "0  241   66   19  149   72   616          70.7   112.1   91.8              1.0  \n",
              "1  414  159   74  352   86  1517          60.8   115.4  102.3              3.0  \n",
              "2   37   32   74   90   94   448          70.6   103.1   93.0              1.0  \n",
              "3  150  106  108  138   72  1293            71     114   93.5              1.0  \n",
              "4   38   37   67   78  122   575          70.7   112.1   91.8              1.0  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6schrQoCyxGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Build the model"
      ]
    },
    {
      "metadata": {
        "id": "uxJ6J_IfxbXA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6851
        },
        "outputId": "a003173d-7e31-471d-bbb3-db6bfd662c61"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12,\n",
        "                kernel_initializer='random_normal',\n",
        "                input_dim=21,\n",
        "                activation='elu'))\n",
        "model.add(Dropout(0))\n",
        "model.add(Dense(8, activation='elu'))\n",
        "model.add(Dense(4, activation='elu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='mean_squared_error', \n",
        "              optimizer=Adam(lr=0.003), \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X.values, y.values,\n",
        "          validation_split=0.3,\n",
        "          epochs=200,\n",
        "          batch_size=20)\n",
        "\n",
        "# # Make predictions with the model\n",
        "# predictions = model.predict(x_pre.values)\n",
        "# print(predictions)\n",
        "# rounded = [round(x[0]) for x in predictions]\n",
        "# print(rounded)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 142 samples, validate on 61 samples\n",
            "Epoch 1/200\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.2785 - acc: 0.7183 - val_loss: 0.0018 - val_acc: 1.0000\n",
            "Epoch 2/200\n",
            "142/142 [==============================] - 0s 127us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0014 - val_acc: 1.0000\n",
            "Epoch 3/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 4/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0012 - val_acc: 1.0000\n",
            "Epoch 5/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 6/200\n",
            "142/142 [==============================] - 0s 143us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 7/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 8/200\n",
            "142/142 [==============================] - 0s 108us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 9/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 10/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 11/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 12/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 13/200\n",
            "142/142 [==============================] - 0s 152us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 14/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 15/200\n",
            "142/142 [==============================] - 0s 136us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 16/200\n",
            "142/142 [==============================] - 0s 123us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 17/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 18/200\n",
            "142/142 [==============================] - 0s 144us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 19/200\n",
            "142/142 [==============================] - 0s 197us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 20/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 21/200\n",
            "142/142 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 22/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 23/200\n",
            "142/142 [==============================] - 0s 131us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 24/200\n",
            "142/142 [==============================] - 0s 171us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 25/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 26/200\n",
            "142/142 [==============================] - 0s 154us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 27/200\n",
            "142/142 [==============================] - 0s 135us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 28/200\n",
            "142/142 [==============================] - 0s 170us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 29/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 30/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 31/200\n",
            "142/142 [==============================] - 0s 136us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 32/200\n",
            "142/142 [==============================] - 0s 100us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 33/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 34/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 35/200\n",
            "142/142 [==============================] - 0s 168us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 36/200\n",
            "142/142 [==============================] - 0s 88us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 37/200\n",
            "142/142 [==============================] - 0s 101us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 38/200\n",
            "142/142 [==============================] - 0s 160us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 39/200\n",
            "142/142 [==============================] - 0s 137us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 40/200\n",
            "142/142 [==============================] - 0s 205us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 41/200\n",
            "142/142 [==============================] - 0s 133us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 42/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 43/200\n",
            "142/142 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 44/200\n",
            "142/142 [==============================] - 0s 164us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 45/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 46/200\n",
            "142/142 [==============================] - 0s 132us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 47/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 48/200\n",
            "142/142 [==============================] - 0s 135us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 49/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 50/200\n",
            "142/142 [==============================] - 0s 105us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 51/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 52/200\n",
            "142/142 [==============================] - 0s 124us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 53/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 54/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 55/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 56/200\n",
            "142/142 [==============================] - 0s 151us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 57/200\n",
            "142/142 [==============================] - 0s 132us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 58/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 59/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 60/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 61/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 62/200\n",
            "142/142 [==============================] - 0s 118us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 63/200\n",
            "142/142 [==============================] - 0s 108us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 64/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 65/200\n",
            "142/142 [==============================] - 0s 127us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 66/200\n",
            "142/142 [==============================] - 0s 153us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 67/200\n",
            "142/142 [==============================] - 0s 133us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 68/200\n",
            "142/142 [==============================] - 0s 123us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 69/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 70/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 71/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 72/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 73/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 74/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 75/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 76/200\n",
            "142/142 [==============================] - 0s 107us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 77/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 78/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 79/200\n",
            "142/142 [==============================] - 0s 141us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 80/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 81/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 82/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 83/200\n",
            "142/142 [==============================] - 0s 131us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 84/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 85/200\n",
            "142/142 [==============================] - 0s 115us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 86/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 87/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 88/200\n",
            "142/142 [==============================] - 0s 149us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 89/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 90/200\n",
            "142/142 [==============================] - 0s 125us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 91/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 92/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 93/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 94/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 95/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 96/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 97/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 98/200\n",
            "142/142 [==============================] - 0s 131us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 99/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 100/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 101/200\n",
            "142/142 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 102/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 103/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 104/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 105/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 106/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 107/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 108/200\n",
            "142/142 [==============================] - 0s 131us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 109/200\n",
            "142/142 [==============================] - 0s 118us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 110/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 111/200\n",
            "142/142 [==============================] - 0s 115us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 112/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 113/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 114/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 115/200\n",
            "142/142 [==============================] - 0s 131us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 116/200\n",
            "142/142 [==============================] - 0s 115us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 117/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 118/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 119/200\n",
            "142/142 [==============================] - 0s 124us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 120/200\n",
            "142/142 [==============================] - 0s 125us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 121/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 122/200\n",
            "142/142 [==============================] - 0s 108us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 123/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 124/200\n",
            "142/142 [==============================] - 0s 124us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 125/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 126/200\n",
            "142/142 [==============================] - 0s 103us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 127/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 128/200\n",
            "142/142 [==============================] - 0s 138us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 129/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 130/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 131/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 132/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 133/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 134/200\n",
            "142/142 [==============================] - 0s 95us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 135/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 136/200\n",
            "142/142 [==============================] - 0s 136us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 137/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 138/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 139/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 140/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 141/200\n",
            "142/142 [==============================] - 0s 113us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 142/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 143/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 144/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 145/200\n",
            "142/142 [==============================] - 0s 125us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 146/200\n",
            "142/142 [==============================] - 0s 133us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 147/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 148/200\n",
            "142/142 [==============================] - 0s 108us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 149/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 150/200\n",
            "142/142 [==============================] - 0s 140us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 151/200\n",
            "142/142 [==============================] - 0s 116us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 152/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 153/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 154/200\n",
            "142/142 [==============================] - 0s 136us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 155/200\n",
            "142/142 [==============================] - 0s 140us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 156/200\n",
            "142/142 [==============================] - 0s 142us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 157/200\n",
            "142/142 [==============================] - 0s 130us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 158/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 159/200\n",
            "142/142 [==============================] - 0s 103us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 160/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 161/200\n",
            "142/142 [==============================] - 0s 128us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 162/200\n",
            "142/142 [==============================] - 0s 123us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 163/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 164/200\n",
            "142/142 [==============================] - 0s 115us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 165/200\n",
            "142/142 [==============================] - 0s 132us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 166/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 167/200\n",
            "142/142 [==============================] - 0s 124us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 168/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 169/200\n",
            "142/142 [==============================] - 0s 143us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 170/200\n",
            "142/142 [==============================] - 0s 107us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 171/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 172/200\n",
            "142/142 [==============================] - 0s 106us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 173/200\n",
            "142/142 [==============================] - 0s 122us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 174/200\n",
            "142/142 [==============================] - 0s 127us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 175/200\n",
            "142/142 [==============================] - 0s 135us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 176/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 177/200\n",
            "142/142 [==============================] - 0s 133us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 178/200\n",
            "142/142 [==============================] - 0s 117us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 179/200\n",
            "142/142 [==============================] - 0s 120us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 180/200\n",
            "142/142 [==============================] - 0s 109us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 181/200\n",
            "142/142 [==============================] - 0s 125us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 182/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 183/200\n",
            "142/142 [==============================] - 0s 121us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 184/200\n",
            "142/142 [==============================] - 0s 127us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 185/200\n",
            "142/142 [==============================] - 0s 112us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 186/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 187/200\n",
            "142/142 [==============================] - 0s 130us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 188/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 189/200\n",
            "142/142 [==============================] - 0s 153us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 190/200\n",
            "142/142 [==============================] - 0s 127us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 191/200\n",
            "142/142 [==============================] - 0s 126us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 192/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 193/200\n",
            "142/142 [==============================] - 0s 111us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 194/200\n",
            "142/142 [==============================] - 0s 125us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 195/200\n",
            "142/142 [==============================] - 0s 118us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 196/200\n",
            "142/142 [==============================] - 0s 108us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 197/200\n",
            "142/142 [==============================] - 0s 134us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 198/200\n",
            "142/142 [==============================] - 0s 119us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 199/200\n",
            "142/142 [==============================] - 0s 114us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n",
            "Epoch 200/200\n",
            "142/142 [==============================] - 0s 110us/step - loss: 0.1831 - acc: 0.8169 - val_loss: 0.0011 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6d634a24e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "metadata": {
        "id": "WCL6JGr7xojP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}